{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "story = []\n",
    "for filename in os.listdir('archive'):\n",
    "        \n",
    "    for file in os.listdir(\"archive\"):\n",
    "        file_path = os.path.join('archive', file)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            corpus = f.read()\n",
    "            \n",
    "        raw_sent = sent_tokenize(corpus)\n",
    "        for sent in raw_sent:\n",
    "            story.append(simple_preprocess(sent)) # conveting sentace to token\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sentances in 5 books: 794370\n"
     ]
    }
   ],
   "source": [
    "print(\"total sentances in 5 books:\",len(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(story):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    story_without_stopwords = [\n",
    "        [word for word in sentence if word not in stop_words] for sentence in story\n",
    "    ]\n",
    "    return story_without_stopwords                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_without_stopwords = remove_stopwords(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(story_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22252134, 22981575)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story_without_stopwords, total_examples=model.corpus_count , epochs=model.epochs)\n",
    "\n",
    "# total_examples=model.corpus_count: Specifies the total number of examples (sentences) in the corpus.\n",
    "# epochs=model.epochs: Specifies the number of epochs to train the model. This is typically set when initializing the model and controls how many times the model will loop through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soldiers', 0.5656920075416565),\n",
       " ('folk', 0.5134671926498413),\n",
       " ('people', 0.5056618452072144),\n",
       " ('captives', 0.5037062168121338),\n",
       " ('score', 0.49859097599983215),\n",
       " ('peasants', 0.498380571603775),\n",
       " ('others', 0.48351189494132996),\n",
       " ('followers', 0.48249033093452454),\n",
       " ('wildlings', 0.4738602638244629),\n",
       " ('greatswords', 0.47337204217910767)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('men')  # most similarword to men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jon'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['jon','rikon','robb','arya','sansa','bran']) # odd one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'women'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['men','women','people','soldiers']) #odd one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5771384 , -0.7151952 ,  3.7712574 , -2.6787608 ,  1.5797927 ,\n",
       "        0.1392476 ,  0.5251375 , -1.9202596 , -1.4973469 ,  0.53023744,\n",
       "        2.0728035 ,  1.7878767 , -1.1621332 , -2.8978019 ,  1.7839115 ,\n",
       "        1.0978525 , -5.111529  ,  1.5894562 , -1.585205  ,  0.07150149,\n",
       "       -2.378969  , -0.80677587, -1.1849296 , -1.2879672 ,  3.3328748 ,\n",
       "        0.528752  ,  1.8841935 ,  0.01483119, -1.8933223 ,  0.5516699 ,\n",
       "       -0.3771124 , -1.2351842 , -0.41908258,  3.3310723 ,  1.0906845 ,\n",
       "        3.1497674 , -0.50988996, -0.55805874,  0.84068155,  0.8821346 ,\n",
       "       -2.785543  , -1.3856261 , -0.42816633,  1.4846216 ,  1.8556056 ,\n",
       "       -0.48747855,  1.5253853 ,  1.6660981 , -1.4199165 ,  1.3328782 ,\n",
       "       -0.999172  ,  0.1280612 ,  1.5000963 , -0.42765248,  3.1555078 ,\n",
       "       -1.5696329 , -3.869574  ,  0.85776603,  1.1417781 , -2.2143886 ,\n",
       "        0.79996806,  0.7939458 , -1.8644264 ,  1.8326398 , -1.2315683 ,\n",
       "       -1.1296937 , -0.32467994,  0.78172797, -0.2074669 , -0.6244943 ,\n",
       "        0.94814676, -0.00529375,  2.9549582 ,  0.38241935, -1.3024738 ,\n",
       "        0.09430625, -1.5948033 ,  0.44431213,  3.9456234 , -0.2769961 ,\n",
       "       -3.2818923 , -2.417686  , -0.95099056,  1.5544344 ,  1.6369939 ,\n",
       "       -0.4961867 , -2.3932889 ,  1.0484245 ,  2.0135422 ,  0.7437706 ,\n",
       "       -0.4530588 , -0.5331428 , -0.643334  ,  0.93580616, -0.5490754 ,\n",
       "       -0.34394863, -0.989489  , -1.1331642 ,  3.601824  ,  1.6028583 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24079, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_normed_vectors().shape # total number of word2vec vector with there dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24079"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key) # total number of words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpupy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
